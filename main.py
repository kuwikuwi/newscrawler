#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
í†µí•© ë‰´ìŠ¤ í¬ë¡¤ëŸ¬
Google Newsì™€ Naver Newsì—ì„œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í†µí•© í”„ë¡œê·¸ë¨
"""

import sys
import os
from pathlib import Path

# Add src directory to Python path
sys.path.append(str(Path(__file__).parent / 'src'))

from src.crawlers import GoogleNewsCrawler, NaverNewsCrawler
from src.config import Config

def get_user_input():
    """ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ í¬ë¡¤ë§ ì„¤ì •ì„ ë°˜í™˜"""
    print("=" * 50)
    print("    í†µí•© ë‰´ìŠ¤ í¬ë¡¤ëŸ¬")
    print("=" * 50)
    
    # ê²€ìƒ‰ì–´ ì…ë ¥
    query = input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    if not query:
        print("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
        return None
    
    # ë‰´ìŠ¤ ì†ŒìŠ¤ ì„ íƒ
    print("\në‰´ìŠ¤ ì†ŒìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. Google News")
    print("2. Naver News")
    print("3. ë‘˜ ë‹¤")
    
    source_choice = input("ì„ íƒ (1-3): ").strip()
    
    sources = []
    if source_choice == '1':
        sources = ['google']
    elif source_choice == '2':
        sources = ['naver']
    elif source_choice == '3':
        sources = ['google', 'naver']
    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. Google Newsë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        sources = ['google']
    
    # ìµœëŒ€ í˜ì´ì§€ ìˆ˜
    try:
        max_pages = int(input("ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸ê°’ 5): ") or "5")
        max_pages = max(1, min(max_pages, 20))  # 1-20 ë²”ìœ„ë¡œ ì œí•œ
    except ValueError:
        max_pages = 5
    
    # ì •ë ¬ ì˜µì…˜ (Naverìš©)
    sort_option = '0'  # ê¸°ë³¸ê°’: ê´€ë ¨ì„±
    if 'naver' in sources:
        print("\nì •ë ¬ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš” (Naver News):")
        print("1. ê´€ë ¨ì„±ìˆœ")
        print("2. ìµœì‹ ìˆœ")
        
        sort_choice = input("ì„ íƒ (1-2, ê¸°ë³¸ê°’ 1): ").strip()
        sort_option = '1' if sort_choice == '2' else '0'
    
    # ì‹œê°„ ë²”ìœ„ (Googleìš©)
    time_range = '1d'  # ê¸°ë³¸ê°’: 1ì¼
    if 'google' in sources:
        print("\nì‹œê°„ ë²”ìœ„ë¥¼ ì„ íƒí•˜ì„¸ìš” (Google News):")
        print("1. 1ì‹œê°„")
        print("2. 1ì¼")
        print("3. 1ì£¼")
        print("4. 1ê°œì›”")
        
        time_choice = input("ì„ íƒ (1-4, ê¸°ë³¸ê°’ 2): ").strip()
        time_map = {'1': '1h', '2': '1d', '3': '1w', '4': '1m'}
        time_range = time_map.get(time_choice, '1d')
    
    return {
        'query': query,
        'sources': sources,
        'max_pages': max_pages,
        'sort': sort_option,
        'time_range': time_range
    }

def run_crawler(crawler, query, **kwargs):
    """í¬ë¡¤ëŸ¬ ì‹¤í–‰"""
    try:
        print(f"\n{crawler.get_source_name()} í¬ë¡¤ë§ ì‹œì‘...")
        results = crawler.crawl(query, **kwargs)
        
        if results:
            filename = crawler.save_results(query)
            print(f"âœ… {len(results)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ")
            print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {filename}")
            return True
        else:
            print("âŒ ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
            
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        config = get_user_input()
        if not config:
            return
        
        print(f"\nğŸ” ê²€ìƒ‰ì–´: {config['query']}")
        print(f"ğŸ“° ì†ŒìŠ¤: {', '.join(config['sources']).upper()}")
        print(f"ğŸ“„ ìµœëŒ€ í˜ì´ì§€: {config['max_pages']}")
        
        # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
        Config.ensure_result_dir()
        
        success_count = 0
        
        # Google News í¬ë¡¤ë§
        if 'google' in config['sources']:
            google_crawler = GoogleNewsCrawler()
            if run_crawler(
                google_crawler, 
                config['query'],
                max_pages=config['max_pages'],
                time_range=config['time_range']
            ):
                success_count += 1
        
        # Naver News í¬ë¡¤ë§
        if 'naver' in config['sources']:
            naver_crawler = NaverNewsCrawler()
            if run_crawler(
                naver_crawler,
                config['query'],
                max_pages=config['max_pages'],
                sort=config['sort']
            ):
                success_count += 1
        
        # ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 50)
        if success_count > 0:
            print("ğŸ‰ í¬ë¡¤ë§ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"ğŸ“Š {success_count}ê°œ ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        else:
            print("âš ï¸  í¬ë¡¤ë§ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        print("=" * 50)
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()